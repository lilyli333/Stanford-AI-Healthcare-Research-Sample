# Stanford-AI-Healthcare-Research-Sample
Image classification of sensor data using CNN model 

	OVERVIEW
A 6-layered Convolutional Neural Network (3 convolutional layers, 1 flattening layer, and 2 fully connected layers) using the Tensorflow open source library was constructed to complete this research sample. This layering structure was chosen in order to have an output size of 28 x 28 x 6. After running this model three times on an Apple MacBook Pro (processor: 3.1 GHz Intel Core i5; memory: 16GB 2133 MHz LPDDR3; graphics: Intel Iris Graphics 550 1536 MB), the highest validation set classification accuracy was 96.9%. The entire dataset of files was divided into an 8:2 ratio of training and validation sub-sets respectively in order to ensure the highest accuracy possible. By using an 8:2 split for the dataset, a sufficient number of images are aside for validation while the largest possible number of images was used for training. An additional sample of 100 images from different sensors was set aside to ensure that overfitting does not occur when the model predicts new images.
	
 	 DATA AND METHODS
In order to maximize the accuracy of the training process, the entire dataset of images was used for training, except for 50 ‘0’ images and 50 ‘1’ images which were saved for predicting purposes. In order to pre-process the ‘.npz’ files, they were first formatted into arrays and normalized using the formula (p-imgMin)/(imgMax-imgMin) (where p is each array value, imgMin is the minimum value of the array, and imgMax the maximum). Finally, the arrays were reshaped using the resize() method from the scikit-image library in order to obtain the desired dimensions of 128 x 128. This dimension was mathematically determined for the purpose of efficiently calculating the correct parameters of each layer during construction.
